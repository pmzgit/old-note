## 图灵机
* 可计算性理论
## 冯·诺依曼体系结构
* 运算器、控制器、存储器、输入设备和输出设备

## cpu
* 算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的处理器单元（Processing Unit），用来完成各种算术和逻辑运算。
* 指令寄存器（Instruction Register）和程序计数器（Program Counter）的控制器单元（Control Unit/CU），用来控制程序的流程

## 思维导图
![](./assets/计算机组成原理-思维导图.jpg)

### 性能
性能指标：响应时间 + 吞吐率    
性能定义：1 / 响应时间  
计算机的计时单位：CPU 时钟,程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time。(sh: time)  
程序的 CPU 执行时间 = 指令数×CPI（Cycles Per Instruction，简称 CPI）×Clock Cycle Time 

### 性能提升
* 功耗 ~= 1/2 ×负载电容×电压的平方×开关频率×晶体管数量

想要计算得快，一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是增加密度，提升**制程**；另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是提升主频。而这两者，都会增加功耗，带来**耗电和散热**的问题。

降低电压，功耗平方指数级降低

* 并行优化  
前提：符合 forkjoin 任务模型  
优化计算规律：阿姆达尔定律：优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间

* 加速大概率事件：向量与矩阵计算： cpu->gpu->tpu

* 通过流水线提高性能：指令分工

* 通过预测提高性能：分支和冒险、“局部性原理”

# 计算机指令和运算

## 指令集

* 高级语言->汇编语言->机器码
* 汇编代码（ASM，Assembly Language）和机器码之间是一一对应的
* 指令集：算术类、逻辑类、条件分支类、数据传输类（给变量赋值、在内存里读写数据）、无条件跳转（调用函数）

## 寄存器  
逻辑上，我们可以认为，CPU 其实就是由一堆寄存器组成的。而寄存器就是 CPU 内部，由多个触发器（Flip-Flop）或者锁存器（Latches）组成的简单电路。N 个触发器或者锁存器，就可以组成一个 N 位（Bit）的寄存器，能够保存 N 位的数据。比方说，我们用的 64 位 Intel 服务器，寄存器就是 64 位的。触发器和锁存器，其实就是两种不同原理的数字电路组成的逻辑门
### 分类与运行
* PC 寄存器：指令地址寄存器、指令寄存器、条件码寄存器、其他用来存储数据和内存地址的寄存器
* 一个程序执行的时候，CPU 会根据 PC 寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载。

## cpu执行：指令封装与复用
* 内存栈：函数间调用，通过压栈帧（返回地址、参数列表）和出栈帧，在指令跳转的过程种，加入了一个“记忆”的功能，能够实现更加丰富和灵活的指令执行流程
* 优化：编译时内联（原因：CPU 需要执行的指令数变少了，根据地址跳转的过程不需要了，压栈和出栈的过程也不用了。缺点：程序占用空间变大），避免栈溢出（减少参数列表或者函数作用域里面的临时变量的占用内存，避免递归层数过深）

## 编译、链接和装载
* C 语言代码，可以通过编译器编译成汇编代码，然后汇编代码再通过汇编器变成 CPU 可以理解的机器码也叫：目标文件（Object File）。再通过链接器（Linker）把多个目标文件以及调用的各种函数库（os相关：系统调用，动态链接库）链接起来，我们才能得到一个可执行文件。
* 第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成，生成了一个可执行文件。第二部分，我们通过装载器（Loader）把可执行文件装载（Load）到内存中。CPU 从内存中读取指令和数据，来开始真正执行程序。
* Linux 下，可执行文件和目标文件所使用的都是一种叫 ELF（Execuatable and Linkable File Format）的文件格式，中文名字叫可执行与可链接文件格式
* elf与静态链接机制   
ELF 文件格式把各种信息，分成一个一个的 Section 保存起来。ELF 有一个基本的文件头（File Header），用来表示这个文件的基本属性，比如是否是可执行文件，对应的 CPU、操作系统等等。代码段，数据段，重定位表（Relocation Table），符号表（Symbol Table）。符号表保留了我们所说的当前文件里面定义的函数名称和对应地址的地址簿。

* Windows 的可执行文件格式是一种叫作 PE（Portable Executable Format）的文件格式。
* 装载器：wine、wsl
* 高级语言：Java的类加载是由jvm完成，大致过程为装载-链接-初始化-运行，所以是jvm帮我们屏蔽了操作系统之间的差异。为了加快程序启动速度，一些类会延迟加载，所以jvm中有很多动态链接。

### 程序装载
* 要求
1. 可执行程序加载后占用的内存空间应该是连续的:程序计数器是顺序地一条一条指令执行下去
2. 我们需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置（让程序不需要考虑实际的物理内存地址、大小和当前连续分配空间问题）。
* 解决方案：加入一个间接层
1. 内存页映射：虚拟内存地址（Virtual Memory Address 指令里用到的内存地址，对于任何一个程序来说，它看到的都是同样的内存地址）与物理内存地址（Physical Memory Address实际在内存硬件里面的空间地址）映射表。
2. 内存分页： getconf PAGE_SIZE（4096）
3. 内存交换与虚拟内存：分配映射表后可以延迟加载，当cpu发出内存缺页错误（Page Fault，还没有加载或者交换出去在硬盘上），os将对应的页，从存放在硬盘上的虚拟内存里读取出来，加载到物理内存里。

### 动态链接
* 编译出来的共享库文件的指令代码，是地址无关码（Position-Independent Code）。动态代码库内部的变量和函数调用，使用相对地址（Relative Address）。
* 动态链接的解决方案：
1. 程序链接表（Procedure Link Table）里面找要调用的函数。
2. 在动态链接对应的共享库，我们在共享库的 data section 里面，保存了一张全局偏移表（GOT，Global Offset Table）。虽然共享库的代码部分的物理内存是共享的，但是数据部分是各个动态链接它的应用程序里面各加载一份的。所有需要引用当前共享库外部的地址的指令，都会查询 GOT，来找到当前运行程序的虚拟内存里的对应位置。而 GOT 表里的数据，则是在我们加载一个个共享库的时候写进去的。不同的进程，调用同样的 lib.so，各自 GOT 里面指向最终加载的动态链接库里面的虚拟内存地址是不同的。
3. PLT是为了做延迟绑定，如果函数没有实际被调用到，就不需要更新GOT里面的数值。因为很多动态装载的函数库都是不会被实际调用到的。
* **不仅能够做到代码在开发阶段的复用，也能做到代码在运行阶段的复用。**

### 二进制编码
* ASCII 码里面，数字 9 不再像整数表示法里一样，用 0000 1001 来表示，而是用 0011 1001 来表示。字符串 15 也不是用 0000 1111 这 8 位来表示，而是变成两个字符 1 和 5 连续放在一起，也就是 0011 0001 和 0011 0101，需要用两个 8 位来表示。
* 字符集（Charset）和字符编码（Character Encoding）: Unicode，其实就是一个字符集，包含了 150 种语言的 14 万个不同的字符。而字符编码则是对于字符集里的这些字符，怎么一一用二进制表示出来的一个字典

### 门电路
* 继电器（Relay）：中继，其实就是不断地通过新的电源重新放大已经开始衰减的原有信号
* 反向器（Inverter）:反向器的电路，其实就是开关从默认关闭变成默认开启而已
* 门电路，叫作组合逻辑电路。与、或、非,异或（XOR）门
### 加法器(超前进位加法器)
* 通过一个异或门计算出个位，通过一个与门计算出是否进位，我们就通过电路算出了一个一位数的加法。于是，我们把两个门电路打包，给它取一个名字，就叫作半加器（Half Adder）。
* 我们用两个半加器和一个或门，就能组合成一个全加器。
* 8 位加法器可以由 8 个全加器串联而成
* 程序知道运算溢出的原因
* https://nieyong.github.io/wiki_cpu/CPU%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84-RISC%E5%92%8CCISC.html
### 乘法器
* 是用更少更简单的电路，但是需要更长的门延迟和时钟周期；还是用更复杂的电路，但是更短的门延迟和时钟周期来计算一个复杂的指令，这之间的权衡，其实就是计算机体系结构中 RISC 和 CISC 的经典历史路线之争。

### 进制转换与表示
* 整数  
十进制转换为二进制: 除2取余，逆序排列  
二进制转换为十进制 : 按权相加法  
* 实数   
十进制转换为二进制：   
整数部分除 2 取余，逆序排列，小数部分乘 2 取整，顺序排列  
二进制转换为十进制： 按权相加法 

### 浮点数据的存储导致精度损失
* 先转成二进制，在转成IEEE754
* IEEE 754：浮点型分为符号位,指数位和有效位，x=(−1)S×(1.M)×2e，符号位 S：0是正数, 1是负数，指数位 e（指数位在这里兼具了需要表示正负的责任，它规定最大值/2 - 1表示指数0，单精度浮点数指数区域能够表示的最大数为2^8-1 = 255，那么255/2 - 1 = 127, 127代表指数0，128代表指数1, 126代表指数-1），有效位M（浮点数据的小数部分）

### 精度运算解决方案
* 转换成整型
* 使用Decimal函数
* 大数吃小数：[Kahan_summation_algorithm](https://en.wikipedia.org/wiki/Kahan_summation_algorithm)

# 处理器
## 指令+计算
### 指令周期（Instruction Cycle）
* Fetch（取得指令），也就是从 PC 寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令，加载到指令寄存器中，然后把 PC 寄存器自增，好在未来执行下一条指令。
* Decode（指令译码），也就是根据指令寄存器里面的指令，解析成要进行什么样的操作，是 R、I、J 中的哪一种指令，具体要操作哪些寄存器、数据或者内存地址。
* Execute（执行指令），也就是实际运行对应的 R、I、J 这些特定的指令，进行算术逻辑操作、数据传输或者直接的地址跳转。

![](./assets/指令周期.jpeg)
* 指令译码器将输入的机器码，解析成不同的操作码和操作数，然后传输给 ALU 进行计算
* 对于一个指令周期来说，我们取出一条指令，然后执行它，至少需要两个 CPU 周期。从内存里面读取一条指令的最短时间，称为 CPU 周期，复杂的指令则需要更多的 CPU 周期.一个指令周期，包含多个 CPU 周期，而一个 CPU 周期包含多个时钟周期。
### 组合逻辑电路和时序逻辑电路（自动运行，存储，时序协调）
* ALU 这样的组合逻辑电路、用来存储数据的锁存器和 D 触发器电路、用来实现 PC 寄存器的计数器电路，以及用来解码和寻址的译码器电路。
* 逻辑1和0的本质，是电压：在高电压区域的一个范围，对应数字逻辑1；在低电压区的一个范围，代表数字逻辑0，也就是所谓的高低电平。
* 反馈电路（Feedback Circuit）：把电路的输出信号作为输入信号，再回到当前电路，反相器（Inverter），非门，能够产生时钟信号。通过“外频 + 倍频“的方式来实现高频率的时钟信号
* 寄存器：通过 D 型触发器来构造,一个 D 型触发器，只能控制 1 个比特的读写，但是如果我们同时拿出多个 D 型触发器并列在一起，并且把用同一个 CLK 信号控制作为所有 D 型触发器的开关，这就变成了一个 N 位的 D 型触发器，也就可以同时控制 N 位的读写。。（当两个开关都断开的时候，最终的输出结果，取决于之前动作的输出结果，这个也就是我们说的记忆功能）。电路的输出信号不单单取决于当前的输入信号，还要取决于输出信号之前的状态。最常见的这个电路就是我们的 D 触发器，它也是我们实际在 CPU 内实现存储功能的寄存器的实现方式。
![](./assets\cpu_pc.jpg)
* 每次自增之后，我们可以去对应的 D 型触发器里面取值，这也是我们下一条需要运行指令的地址。前面第 5 讲我们讲过，同一个程序的指令应该要顺序地存放在内存里面。这里就和前面对应上了，顺序地存放指令，就是为了让我们通过程序计数器就能定时地不断执行新指令。
### cpu 运行
![](./assets\cpu_run.jpeg)
* 通过流水线、分支预测等技术，来实现在一个周期里同时执行多个指令。
* 无条件跳转并不涉及到alu的计算，因此，可以直接设置PC寄存器中的值来实现跳转

## 面向流水线的指令设计
* 提高吞吐率（流水线深度+CPU主频同时增加）：在同一时间，同时执行 5 条不同指令的不同阶段，ARM 或者 Intel 的 CPU，流水线级数都已经到了 14 级。但是，每增加一级的流水线，就要多一级写入到流水线寄存器（Pipeline Register）的操作。虽然流水线寄存器非常快，比如只有 20 皮秒（ps，10−12 秒），但深度增加，占比增加。
* 数据冒险，结构冒险、控制冒险：解决方案：乱序执行、分支预测，分级不要太多（多线程不适合有依赖关系的逻辑运算）
### 结构冒险（本质上是一个硬件层面的资源竞争问题）
* 同一个时钟周期，两个不同指令访问同一个资源：现代 CPU 架构，借鉴了哈佛架构，在高速缓存层面拆分成指令缓存和数据缓存，它会从主内存把指令和数据加载到高速缓存中，这样后续的访问都是访问高速缓存。
### 数据冒险：三种不同的依赖关系
* 先写后读（数据依赖），先读后写（反依赖），写后再写（输出依赖）。除了读之后再进行读，你会发现，对于同一个寄存器或者内存地址的操作，都有明确强制的顺序要求。而这个顺序操作的要求，也为我们使用流水线带来了很大的挑战。
* 解决：在进行指令译码的时候，会拿到对应指令所需要访问的寄存器和内存地址。所以，在这个时候，我们能够判断出来，这个指令是否会触发数据冒险（实际的CPU硬件里面有专门的冒险检测电路。）。如果会触发数据冒险，我们就可以决定，让整个流水线停顿一个或者多个周期（插入一个 NOP 操作，也就是执行一个其实什么都不干的操作，又被叫作流水线冒泡（Pipeline Bubble））。该方案是以牺牲 CPU 性能为代价的。因为，实际上在最差的情况下，我们的流水线架构的 CPU，又会退化成单指令周期的 CPU 了。delay slot是MIPS对这个的具体实现和解决方案

### 操作数前推
* 通过 NOP 操作进行对齐：有些指令没有对应的流水线阶段，但是我们并不能跳过对应的阶段直接执行下一阶段。不然，如果我们先后执行一条 LOAD 指令和一条 ADD 指令，就会发生 LOAD 指令的 WB 阶段和 ADD 指令的 WB 阶段，在同一个时钟周期发生。这样，相当于触发了一个结构冒险事件，产生了资源竞争。各个指令不需要的阶段，并不会直接跳过，而是会运行一次 NOP 操作。通过插入一个 NOP 操作，我们可以使后一条指令的每一个 Stage，一定不和前一条指令的同 Stage 在一个时钟周期执行。
* 指令对齐和流水线冒泡导致的cpu空转
![](./assets\cpu_数据冒险.jpeg)
* 操作数前推（Operand Forwarding）或操作数旁路（Operand Bypassing）
![](./assets\cpu_操作数转发.jpeg)
在 CPU 的硬件里面，需要再单独拉一根信号传输的线路出来，使得 ALU 的计算结果，能够重新回到 ALU 的输入里来。这样的一条线路，就是我们的“旁路”。它越过（Bypass）了写入寄存器，再从寄存器读出的过程，也为我们节省了 2 个时钟周期。
* 操作数前推的解决方案不但可以单独使用，还可以和流水线冒泡一起使用
![](./assets\cpu_操作数旁路.jpeg)

### 乱序执行
* 整个乱序执行技术，就好像在指令的执行阶段提供一个“线程池”。指令不再是顺序执行的，而是根据池里所拥有的资源，以及各个任务是否可以进行执行，进行动态调度。在执行完成之后，又重新把结果在一个队列里面，按照指令的分发顺序重新排序。即使内部是“乱序”的，但是在外部看起来，仍然是井井有条地顺序执行。
![](./assets\cpu_乱序执行.jpeg)
* 指令执行的先后顺序，不再和它们在程序中的顺序有关。我们只要保证不破坏数据依赖就好了。CPU 只要等到在指令结果的最终提交的阶段，再通过重排序的方式，确保指令“实际上”是顺序执行的。
* https://en.wikipedia.org/wiki/Tomasulo_algorithm
* 保障内存数据访问顺序的模型，叫作强内存模型（Strong Memory Model）
### 控制冒险（Control Harzard）:为了确保能取到正确的指令，而不得不进行等待延迟
* 在结构冒险和数据冒险中，所有的流水线停顿操作都要从指令执行阶段开始，但是条件、循环逻辑等要等 jmp 指令执行完成，去更新了 PC 寄存器之后，我们才能知道，是否执行下一条指令，还是跳转到另外一个内存地址，去取别的指令。
* 控制冒险策略，有缩短分支延迟，分支预测，动态分支预测
* 分支预测：交换内外循环的顺序，因为控制冒险导致性能差异。虽然执行的指令数是一样的，但是分支预测失败得多的程序，性能就要差上几倍。